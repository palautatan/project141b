{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "# TEXT PROCESSING\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# DATA SCIENCE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# VISUALIZATION\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# ELSE\n",
    "from collections import Counter\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTION TO CLEAN UP BODY TEXT\n",
    "def cleanUpText(text, additional_stopwords=[]):\n",
    "    # REMOVE MARK UP\n",
    "    new_text = text.replace(\"\\r\", \"\").replace(\"\\n\", \"\")\n",
    "    \n",
    "    # REMOVE URLS\n",
    "    new_text = re.sub(r\"\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*\", \"\", new_text).strip()\n",
    "    \n",
    "    # REMOVE PUNCTUATION\n",
    "    new_text = new_text.translate(None, string.punctuation)\n",
    "    \n",
    "    # REMOVE NUMBERS\n",
    "    new_text = re.sub(r\"\\d+\", \"\", new_text)\n",
    "    \n",
    "    # LOWERCASE\n",
    "    new_text = new_text.lower()\n",
    "    \n",
    "    #SPLIT\n",
    "    new_text = new_text.split()\n",
    "    \n",
    "    # REMOVE STOPWORDS\n",
    "    stops = stopwords.words(\"english\") + additional_stopwords\n",
    "    \n",
    "    return [word for word in new_text if word not in stops]\n",
    "\n",
    "\n",
    "\n",
    "# FUNCTION TO CLEAN UP BODY TEXT\n",
    "def cleanUpTitle(text):\n",
    "    # REMOVE MARK UP\n",
    "    new_text = text.replace(\"\\r\", \"\").replace(\"\\n\", \"\")\n",
    "    \n",
    "    # REMOVE NUMBERS\n",
    "    new_text = re.sub(r\"\\d+\", \"\", new_text)\n",
    "    \n",
    "    # LOWERCASE\n",
    "    new_text = new_text.lower()\n",
    "    \n",
    "    return(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/EDIE/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:24: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "# READ IN DATA TO TRAIN MODEL\n",
    "petnlp = pd.DataFrame.from_csv(\"petnlp.csv\")\n",
    "\n",
    "cleaned_titles = [cleanUpTitle(x) for x in petnlp[\"title\"]]\n",
    "\n",
    "\n",
    "# DEFINE NEW STOP WORDS\n",
    "new_stops = \"President, president, people, without, needs, since, used, get, would, us, united, states, people, american, americans, national, government, petition, make, also, many, must, need, change, ask, use, every, trump, white, house, america, America, executive, Executive\"\n",
    "new_stops = new_stops.split(\", \")\n",
    "\n",
    "\n",
    "tokens = [cleanUpText(x, new_stops) for x in petnlp[\"body\"]]\n",
    "\n",
    "blobs = [unicode(\" \".join(x), errors=\"replace\") for x in tokens]\n",
    "blobs = [x.encode(\"ascii\", \"replace\") for x in blobs]\n",
    "blobs_df = pd.DataFrame({\"title\":cleaned_titles, \"blobs\":blobs, \"ideology\":petnlp[\"ideology\"]})\n",
    "\n",
    "\n",
    "# REMOVE THE NULLS\n",
    "index = blobs_df[\"ideology\"].index[blobs_df[\"ideology\"].apply(pd.isnull)]\n",
    "blobs_df = blobs_df[~pd.isnull(blobs_df[\"ideology\"])]\n",
    "blobs_df = blobs_df.reset_index(drop=True)\n",
    "\n",
    "# CHOOSE TRAINING DATA\n",
    "train = [32, 262, 136, 240, 22, 24, 33, 66, 115, 84, 197, 246, 127, 88, 125, 224, 90, 23, 211, 168, 249, 156, 164, 239, 186, 155, 29, 185, 234, 232, 192, 218, 74, 113, 14, 172, 161, 47, 85, 244, 56, 207, 105, 46, 44, 142, 13, 199, 117, 7, 67, 18, 221, 145, 189, 71, 179, 242, 171, 52, 60, 152, 195, 162, 86, 147, 120, 245, 139, 256, 93, 220, 8, 62, 91, 82, 75, 96, 94, 223, 39, 151, 5, 250, 188, 3, 34, 35, 16, 259, 203, 124, 77, 238, 11, 101, 37, 194, 233, 76, 243, 149, 102, 236, 258, 260, 166, 158, 116, 144, 108, 205, 248, 57, 21, 235, 80, 255, 61, 150, 252, 38, 253, 17, 89, 148, 68, 123, 12, 58, 109, 170, 231, 191, 196, 119, 209, 237, 6, 122, 78, 103, 206, 28, 217, 20, 48, 54, 204, 193, 69, 43, 143, 112, 118, 1, 154, 219, 30, 190, 169, 0, 176, 198, 180, 19, 59, 137, 107, 135, 175, 131, 36, 27, 153, 140, 216, 2, 261, 126, 104, 110, 51, 87, 187, 121, 98, 132, 95, 79, 247, 50, 92, 133, 70, 157, 167, 214, 159, 163, 184, 160, 15, 97, 178, 225, 202, 173, 26, 63]\n",
    "\n",
    "# VECTORIZING TRAINING DATA\n",
    "vectorizer = CountVectorizer(analyzer= \"word\",\n",
    "                            tokenizer = None,\n",
    "                            preprocessor = None,\n",
    "                            stop_words = None,\n",
    "                            max_features = 5000)\n",
    "train_data_features = vectorizer.fit_transform(blobs_df[\"blobs\"][train])\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "\n",
    "# GENERATE OUR FOREST\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "our_forest = forest.fit(train_data_features, blobs_df[\"ideology\"][train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET INDICES OF TEST DATA\n",
    "test = set(range(len(blobs_df))) - set(train)\n",
    "test = list(test)\n",
    "\n",
    "# VECTORIZING TEST DATA\n",
    "test_data_features = vectorizer.transform(blobs_df[\"blobs\"][test])\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "\n",
    "# PREDICT\n",
    "result = forest.predict(test_data_features)\n",
    "pred_df = pd.DataFrame({\"petition\":blobs_df[\"title\"][test], \"true_ideol\":blobs_df[\"ideology\"][test], \"pred_ideol\":result})\n",
    "pred_df = pred_df.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3962264150943396"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CALCULATE ERROR\n",
    "pred_df[\"correct\"] = (pred_df[\"pred_ideol\"] == pred_df[\"true_ideol\"])\n",
    "\n",
    "# ERROR RATE\n",
    "len(pred_df[pred_df[\"correct\"]==False])*(len(pred_df)**(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
